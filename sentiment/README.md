
# üì∞ Sentiment Analysis Pipeline

The `/sentiment` folder contains the python scripts and files necessary for the execution of the sentiment analysis pipeline as part of the project.
It aims to extract the daily scrapped news from yesterday to obtain a risk score response from the DeepSeek LLM for each **Nvidia stock** related news. The risk scores are then weighted and aggregated into hourly bins in the FinRL format, before passing this data to the inference part of FinRL. 

---

## üîç Purpose

There are 4 python scripts in this directory. The purpose of each script is as follows:

### `data_preprocessing.py`
 - Extracts yesterday's scrapped news about **Nvidia stock** from `scrape/news.csv`
 - Saves this data into `temp/processed_data.json` for the next step in risk score generation

### `risk_score_generation.py`
 - Loads DeepSeek model to analyse each **Nvidia stock** related news content and assigns an investment risk score to it in the range of 1-5 (low risk - high risk)
 - Appends each news data with its risk value into `news_with_risk_score.csv` for tracebility to trace which news has what risk score
 - Saves datetime, source, specific source, and risk score columns temporarily to `temp/date_risk.csv` for the next risk score aggregation step

### `risk_score_aggregation.py`
 - Loads data from `temp/date_risk.csv`
 - Rounds the datetime to the nearest hourly bin (for e.g. 8:30, 9:30 ..)
 - Groups the data by hourly bins, and aggregates the risk score by calculating the average weighted risk score (the weights refer to the optimal weights of the specific source generated by KMeans clustering beforehand)
 - Appends the results of hourly bins with its average weighted risk score into `aggregated_risk_scores.csv` for the next step in FinRL inference stage.

### `main.py`
 - The main script that the workflow runs on
 - Calls the functions in order from `data_preprocessing.py` > `risk_score_generation.py` > `risk_score_aggregation.py`

---

## üì¶ Features

### ‚û§ ‚öñÔ∏è **KMeans Clustering for specific source weights**  
 - In order to improve the performance of the FinRL agent when receiving news sentiment in its trading environment, it is important to note that news from certain sources could have better influence than others. By giving these important sources a higher weight when calculating the average risk score, it gives more emphasis to the news from these important sources.
 - Instead of using random values for the source weights, KMeans Clustering is applied on the specific sources to obtain the optimal weight for each specific source.
 - This project uses a KMeans of n_clusters=4, which was chosen from the elbow method by plotting the Within-Cluster Sum of Squares (wcss) against number of clusters.
 - More information can be found in the jupyter notebook for KMeans in `kmeans_for_weights.ipynb`


### ‚û§ ‚öôÔ∏è **Automated Execution with GitHub Actions**  
 - Runs every Tuesday - Saturday at 10:00 (UTC).
---

### üöÄ How to run the script manually
First, make sure you are in the right directory:

```bash
cd sentiment
```

To install the required libraries, run the following command:

```bash
pip install -r requirements.txt
```

To run the main script, run the following command:

```bash
python main.py
```